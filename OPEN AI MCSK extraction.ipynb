{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg+u+XAXl60iQP1AgLog6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRNaqvi/Common-Sense-Knowledege-Driven-SemanticRule-Base-Ontology-Mapping/blob/main/OPEN%20AI%20MCSK%20extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK9t3pDCaHjO",
        "outputId": "b6143498-476c-48a8-94b4-127bf7a4a657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.5\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cohere tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKO_dmMaatvQ",
        "outputId": "5458ba73-66bf-4b48-da88-fbbd8c518c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.36-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.6)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip\n"
      ],
      "metadata": {
        "id": "gwsqFUHta30Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip check"
      ],
      "metadata": {
        "id": "FmbWdpgoa8BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jedi fastapi kaleido python-multipart uvicorn pycairo\n"
      ],
      "metadata": {
        "id": "C00Ii1ibbSMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y python3-dev libcairo2-dev\n",
        "!pip install pycairo\n"
      ],
      "metadata": {
        "id": "kH5pkPNwbmlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "jXILgjqjb1D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "5sFnkHm3b3Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "doG9PW7Jb4yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install  openpyxl"
      ],
      "metadata": {
        "id": "fs-GxXzQb60Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "W1Rcev6Qb8sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import load_workbook"
      ],
      "metadata": {
        "id": "TaqQfo_ib-4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import Workbook"
      ],
      "metadata": {
        "id": "OKYVjr7ocHJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from platform import python_version"
      ],
      "metadata": {
        "id": "VbSY27IacI9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(python_version()) #print Version"
      ],
      "metadata": {
        "id": "N94hHMUycKXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "1R0kY9YAcMJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "mb8av_rFcN9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "H25HETiPcO-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\" #Setup OpenAI Key whcih needs everytime to call any prompt"
      ],
      "metadata": {
        "id": "mpaU_raccU8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai.api_key)  #verify that API key embeded with the envoirment"
      ],
      "metadata": {
        "id": "3BdhhfescXBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "qu-Ss19sccmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response #Check Response to match the Messages and verify the conenction gpt-4"
      ],
      "metadata": {
        "id": "dvUohMISch3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'use your API key'\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is Common Sense Knowledge?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "wu8e9jVddZRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a conversation with the model Called (chat/completions)\n",
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is common sense knowledge?\"},\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",  # Change this to the model you want to use\n",
        "  messages=conversation,\n",
        "  max_tokens=100\n",
        ")\n"
      ],
      "metadata": {
        "id": "YKkPe3ypeEFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "RgzaxP-meVSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"so we can say commonsense is somethign everyone agreed on for a parrticular context like math teachers ageee 2+2=4 \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=100\n",
        ")"
      ],
      "metadata": {
        "id": "823xMkaIeefm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "BH6tZ2o9elhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"so we can say commonsense is somethign everyone agreed on for a parrticular context like math teachers ageee 2+2=4  did you get my example\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=200\n",
        ")"
      ],
      "metadata": {
        "id": "RAPB56caemkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "GqPbhfiGeyVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"So now we need to create manufactring Commonsense knowledge so tell me what is manufactring Commonsense knowledge we will use MCSK to refer as manufactring Commonsense knowledge  \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "oVrX1PMffNxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "fkBGBA1EfQbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Yes thats exactly what is MCSK is Now i will give you differet types of MCSK patterns and example so we both can agree. once agree we will create more  \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "H3tekRfTfvAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "rL_QY_fbgBXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Example of Requirement MCSK that Requirement in Manufacturing Common Sense Knowledge is the understanding that specific tasks or processes in manufacturing require specific tools, equipment, or conditions to be completed successfully.  \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "sHY66ni0gDnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "e8lmPMGmgcQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"nother type is Precednce MCSK Many manufacturing processes must follow a specific order or sequence of steps. This is often called the process flow workflow that Each step in the process often depends on completing the previous step. This is what you're referring to as precedence. \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "8u3JQmgXgcwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "V_S6N7-QgdTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Another type of MCSK is Causation in manufacturing refers to the cause-and-effect relationships that exist between different steps in a manufacturing process.\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "79NHIZyDgdzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "zBr3W8wBgeRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Another type of MCSK is many manufacturing processes share similarities due to the nature of the tasks involved. its based on material similarity, process similarity, tool similarity, product characteristics similarity, envoirmental similarity.  \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "T6FcPD53gesG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "r7SZMZcUgff8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"No we Refered as a Similarity not association \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "v9tXYXl6gf2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "WTOkkJHwggJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Another type of MCSK is Distinctness the manufacturing processes are distinct due to the materials used, the process  involved, and the requirements of each product is different from each other. \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "0XI86vH7iBCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "-lPSJugTiYrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Another type of MCSK is Part-hood the manufacturing processes are madeup of smaller essentail subprocess or every complex object consist of many multiple parts or objects with shared characteristics can be grouped \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "5qLNeO44ieEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "deAzTXR8inrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Another type of MCSK is performance it's important to note that assessing performance and competitiveness often involves specific knowledge and context that might go beyond 'common' knowledge. It can require detailed information about the particular materials, tools, and processes used, the design's specifics, the market's characteristics, and so on.\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "_dEOWLkgijpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "pSADSuTFiooq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"so now we see there are many types of MCSK lets patterns of MCSK as we identify Requirement,Precedence, Causation, Similarity , Distinctness, Part-Hood and Performance Right ? \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "He9CXqdjikte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "FqIcGx3qipgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"For sure we both on same idea list down the patterns we discuss\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "X6I3HYRCilCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "vJVgCuGyiqWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Now i will give you example of every pattern from manufacturing common sense knowledge about a wooden chair and you will tell me that what you undersood ok?\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "rSmlswFPilQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "SdSIOTFhirLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"let take the example of a wooden Chairin terms of manufactirg . 1. According to Requirement MCSK pattern A wooden chair requires wood. 2. For Precedence MCSK pattern Designing the chair comes before cutting the wood. 3.For Causation MCSK pattern Using low-quality wood causes the chair to be less sturdy. 4.For Similarity MCSK pattern Both a wooden chair and a wooden bed require wood. 5.For Distinctness MCSK pattern A book is made with paper, a chair is made with wood. 6.For Part-Hood MCSK pattern Cutting and joining are parts of the chair-making process. 7.Performance MCSK pattern High-quality wood, leads to a sturdy chair. \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "yEcMEqjJilby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "AXUgXc70ir9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Now Give me MCSK about making a Car But write down against each pattern we have\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "IUproeTjilnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "d1KH5AWciseU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y76QJloPvNk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openpyxl import Workbook, load_workbook\n",
        "\n",
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"MCSK for Wooden Chair\" })\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")\n",
        "\n",
        "response_content = response['choices'][0]['message']['content']\n",
        "print(\"Response Content:\\n\", response_content) # Diagnostic print\n",
        "\n",
        "# Split the response content into lines\n",
        "lines = response_content.split(\"\\n\")\n",
        "\n",
        "# Define the categories\n",
        "categories = [\"Requirement\", \"Precedence\", \"Causation\", \"Similarity\", \"Distinctness\", \"Part-Hood\", \"Performance\"]\n",
        "\n",
        "# Create a dictionary to hold the data for each category\n",
        "data = {category: [] for category in categories}\n",
        "\n",
        "# Process each line in the response\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "    # Identify the category in the line\n",
        "    for category in categories:\n",
        "        if category in line:\n",
        "            # Split the line based on MCSK:\n",
        "            _, item = line.split(\"MCSK:\", 1)\n",
        "            # Strip the item of any leading/trailing spaces\n",
        "            item = item.strip()\n",
        "            # Add the item to the correct category in the data dictionary only if it is not an empty string\n",
        "            data[category].append(item)\n",
        "            break # Break once a match is found\n",
        "\n",
        "print(\"Data Dictionary:\\n\", data) # Diagnostic print\n",
        "\n",
        "# Define the output directory\n",
        "output_dir = '/content/drive/MyDrive/MCSK'\n",
        "\n",
        "# Make sure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the new output file path\n",
        "new_output_file = os.path.join(output_dir, \"New_MCSK.xlsx\")  # use .xlsx\n",
        "\n",
        "# Check if the output file exists\n",
        "if os.path.isfile(new_output_file):\n",
        "    # If it does, load the workbook\n",
        "    book = load_workbook(new_output_file)\n",
        "else:\n",
        "     # If it doesn't, create a new workbook\n",
        "    book = Workbook()\n",
        "    # When a new workbook is created, an empty sheet named \"Sheet\" is also automatically created.\n",
        "    # Let's remove that sheet.\n",
        "    if 'Sheet' in book.sheetnames:\n",
        "        del book['Sheet']\n",
        "\n",
        "# Iterate over each category\n",
        "for key in data.keys():\n",
        "    # If the sheet exists, select it\n",
        "    if key in book.sheetnames:\n",
        "        sheet = book[key]\n",
        "    else:\n",
        "        # If the sheet doesn't exist, create a new one\n",
        "        sheet = book.create_sheet(key)\n",
        "\n",
        "    # Add new data to the sheet\n",
        "    for item in data[key]:\n",
        "        sheet.append([item])\n",
        "\n",
        "# Saving the workbook\n",
        "book.save(new_output_file)\n",
        "print(\"Data saved to Excel.\")\n"
      ],
      "metadata": {
        "id": "-oujVAEUE-5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "UKCEQDWgnBQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "6Wswyrz5zk1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"No just response is like Requires engine , tires ,chassis 2. desgin phase prcedes the manufacturing phase .like that . Like Fill in the blanks against 7 patters you have reuires ,precedes ,cause, smililar, Distinict, part of , performace \"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "JjdYTWtgnBv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "5xX3clNn1aWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "MfVZgEJ_nB8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "gxiqZhzanCJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "tCi1d602nCUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "a2MvrHxynCez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "Qt7QLFKfnCpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "jk-yGbe7nC07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue the conversation\n",
        "conversation.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=conversation,\n",
        "  max_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "RwWd-5KfnC_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KvIwPnQDnDK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "63n4fW8FnDU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
